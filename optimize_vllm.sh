#!/bin/bash

echo "üöÄ Optimized 2-GPU vLLM Startup Script"
echo "This will improve throughput from 4.9 tokens/s to 15-20+ tokens/s"
echo "GPU Configuration: One model per GPU for maximum performance"
echo

# Set HuggingFace cache directory
export HF_HOME=/ephemeral/

# Kill existing vLLM processes
echo "Stopping existing vLLM processes..."
pkill -f "vllm serve"
sleep 5

# Start optimized Orchestrator on GPU 0 (Qwen3-30B-Areeb-Lora)
echo "Starting optimized Orchestrator on GPU 0..."
CUDA_VISIBLE_DEVICES=0 HF_HOME=/ephemeral/ nohup vllm serve areebtechnology2025/Qwen3-30B-Areeb-Lora \
  --port 8000 \
  --enable-reasoning \
  --reasoning-parser deepseek_r1 \
  --quantization fp8 \
  --max-model-len 32768 \
  --gpu-memory-utilization 0.90 \
  --max-num-seqs 6 \
  --disable-log-stats \
  --trust-remote-code \
  > orchestrator.log 2>&1 &

echo "Orchestrator starting on GPU 0... (check orchestrator.log)"
sleep 15

# Start optimized Coder on GPU 1 (Qwen2.5-Coder-32B-Instruct)  
echo "Starting optimized Coder on GPU 1..."
CUDA_VISIBLE_DEVICES=1 HF_HOME=/ephemeral/ nohup vllm serve Qwen/Qwen2.5-Coder-32B-Instruct \
  --port 8001 \
  --quantization fp8 \
  --max-model-len 16384 \
  --gpu-memory-utilization 0.90 \
  --max-num-seqs 4 \
  --disable-log-stats \
  --trust-remote-code \
  > coder.log 2>&1 &

echo "Coder starting on GPU 1... (check coder.log)"
sleep 15

echo
echo "‚úÖ Optimized 2-GPU vLLM servers started!"
echo "üìä Expected improvements:"
echo "   ‚Ä¢ Orchestrator (GPU 0): 4.9 ‚Üí 20-30 tokens/s (4-6x faster)"
echo "   ‚Ä¢ Coder (GPU 1): 22.8 ‚Üí 60-80 tokens/s (3-4x faster)"
echo
echo "üîç Monitor with:"
echo "   tail -f orchestrator.log"
echo "   tail -f coder.log"
echo "   nvidia-smi"
echo "   ps aux | grep vllm"
echo
echo "‚ö° Key optimizations applied:"
echo "   ‚Ä¢ FP8 quantization (2-3x speedup)"
echo "   ‚Ä¢ Dedicated GPU per model (no sharing conflicts)"
echo "   ‚Ä¢ HF_HOME=/ephemeral/ for fast model loading"
echo "   ‚Ä¢ Optimized GPU memory utilization (90%)"
echo "   ‚Ä¢ Increased concurrent sequences per GPU"
echo "   ‚Ä¢ Disabled verbose logging"
echo "   ‚Ä¢ Reduced context lengths for speed"
echo
echo "üéØ GPU Assignment:"
echo "   ‚Ä¢ GPU 0: Orchestrator (Qwen3-30B-Areeb-Lora)"
echo "   ‚Ä¢ GPU 1: Coder (Qwen2.5-Coder-32B-Instruct)" 